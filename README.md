# ğŸ”¤ AutoSuggestion Engine

> **A multilingual, CNN-powered autosuggestion and typo-correction engine with a FastAPI backend, feedback-learning database, and Trie-based prefix search.**

---

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [System Architecture](#system-architecture)
3. [Repository Structure](#repository-structure)
4. [Supported Languages & Regions](#supported-languages--regions)
5. [Component Deep-Dive](#component-deep-dive)
6. [Data Flow](#data-flow)
7. [Quickstart (Local Dev)](#quickstart-local-dev)
8. [Production Deployment](#production-deployment)
9. [Environment Variables](#environment-variables)
10. [API Reference Summary](#api-reference-summary)
11. [Model Architecture](#model-architecture)
12. [Feedback Learning Loop](#feedback-learning-loop)
13. [Project Conventions](#project-conventions)
14. [Documentation Index](#documentation-index)

---

## Overview

The AutoSuggestion Engine is a production-ready, multilingual word-suggestion system. Given a partial input string (prefix), it returns ranked suggestions in the **target script** (e.g., user types English romanization â†’ engine returns Nepali Unicode words).

### âœ¨ Key Capabilities

| Feature | Detail |
|---|---|
| **Prefix Autocomplete** | Trie-based BFS delivers up to 500 candidate matches instantly |
| **CNN Ranking** | INT8-quantized TFLite CNN model re-ranks candidates by learned probability |
| **Feedback Loop** | User selections stored in MySQL; DB results merge with model results (higher priority) |
| **Multi-language** | Nepal (Nepali/English), India (Hindi/Bengali/Tamil/Telugu), Global (English) |
| **Secure API** | JWT signed with HS512, encrypted with Fernet; token expires in 120 minutes |
| **Production-ready** | Env-var config, connection pooling, CORS lockdown, structured logging |

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER / CLIENT                                â”‚
â”‚              Web Browser  Â·  Mobile App  Â·  Any HTTP client         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚  HTTPS / REST
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WEB FRONTEND (Static)                           â”‚
â”‚   web/frontend/index.html  Â·  css/style.css  Â·  js/app.js          â”‚
â”‚   â€¢ Keystroke-triggered fetch to /autocomplete/suggest              â”‚
â”‚   â€¢ Keyboard navigation (â†‘â†“ Enter)                                  â”‚
â”‚   â€¢ On selection â†’ POST /autocomplete/feedback                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚  HTTP to port 8001
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FASTAPI BACKEND  (autocomplete_api.py)             â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  /token      â”‚   â”‚  /suggest          â”‚   â”‚  /feedback       â”‚  â”‚
â”‚  â”‚  Issues      â”‚   â”‚  Trie + CNN        â”‚   â”‚  Upserts rank    â”‚  â”‚
â”‚  â”‚  encrypted   â”‚   â”‚  pipeline          â”‚   â”‚  in MySQL        â”‚  â”‚
â”‚  â”‚  JWT         â”‚   â”‚                    â”‚   â”‚                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Core Security  (core/security.py)                          â”‚    â”‚
â”‚  â”‚  JWT HS512 sign  â†’  Fernet encrypt  â†’  Bearer token         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  CORS Middleware  (core/middleware.py)                      â”‚    â”‚
â”‚  â”‚  CORS_ORIGINS env var  â†’  locked in production              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                        â”‚
               â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MySQL               â”‚    â”‚  In-Memory Inference Engine        â”‚
â”‚  autosuggest_db      â”‚    â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ feedback table â”‚  â”‚    â”‚  â”‚  TrieSearcher               â”‚  â”‚
â”‚  â”‚ input | label  â”‚  â”‚    â”‚  â”‚  BFS prefix â†’ 500 candidatesâ”‚  â”‚
â”‚  â”‚ rank_score     â”‚  â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ region | lang  â”‚  â”‚    â”‚                 â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Connection Pool     â”‚    â”‚  â”‚  TFLite CNN Interpreter     â”‚  â”‚
â”‚  pool_size=5         â”‚    â”‚  â”‚  INT8 quantized             â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  char_map encode â†’ score    â”‚  â”‚
                            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                            â”‚                 â”‚                  â”‚
                            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                            â”‚  â”‚  Feedback Merger            â”‚  â”‚
                            â”‚  â”‚  DB rank < Model rank(999)  â”‚  â”‚
                            â”‚  â”‚  â†’ final top-K list         â”‚  â”‚
                            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OFFLINE PIPELINE (one-time setup)                 â”‚
â”‚                                                                     â”‚
â”‚  Raw CSV Data                                                       â”‚
â”‚      â”‚                                                              â”‚
â”‚      â–¼                                                              â”‚
â”‚  data_preparation/preprocess/                                       â”‚
â”‚    preprocesssing.py  â†’  char_map_{lang}.json   (character index)  â”‚
â”‚    trie.py            â†’  trie_{lang}.json        (prefix trie)     â”‚
â”‚                          labels_{lang}.txt       (vocab list)       â”‚
â”‚      â”‚                                                              â”‚
â”‚      â–¼                                                              â”‚
â”‚  model_trainings/scripts/                                           â”‚
â”‚    model_training.py  â†’  cnn_{lang}.keras        (full Keras model) â”‚
â”‚    convert_tflite.py  â†’  model_{lang}.tflite     (INT8 quantized)   â”‚
â”‚                                                                     â”‚
â”‚  ETL Pipeline  (csv_extractor.py)                                   â”‚
â”‚    extractor.py  â†’  transformer.py  â†’  loader.py                   â”‚
â”‚    MySQL feedback table  â†’  region/lang CSVs in ETL/csv_exports/   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Repository Structure

```
Autosuggestion_Engine/
â”‚
â”œâ”€â”€ config.py                    # Central config: paths, regions, DB, JWT params
â”œâ”€â”€ autocomplete_main.py         # CLI debug engine (interactive prefix tester)
â”œâ”€â”€ csv_extractor.py             # ETL orchestrator: DB â†’ CSV exports
â”œâ”€â”€ migration.py                 # One-shot DB schema migration runner
â”œâ”€â”€ requirements.txt             # All Python dependencies
â”œâ”€â”€ .env                         # Secrets: JWT_SECRET_KEY, FERNET_KEY, CORS_ORIGINS
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ autocomplete_api.py  # FastAPI app â€” all routes, lifespan, inference
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py      # JWT creation/verification + Fernet encryption
â”‚   â”‚   â”‚   â””â”€â”€ middleware.py    # CORS middleware setup
â”‚   â”‚   â””â”€â”€ database/
â”‚   â”‚       â””â”€â”€ db.py            # MySQL connection pool, init_db, update_rank, get_rank
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ index.html           # Single page autocomplete UI
â”‚       â”œâ”€â”€ css/style.css        # Responsive styles
â”‚       â””â”€â”€ js/app.js            # Fetch suggestions, keyboard nav, send feedback
â”‚
â”œâ”€â”€ data_preparation/
â”‚   â”œâ”€â”€ preprocess/
â”‚   â”‚   â”œâ”€â”€ preprocesssing.py    # Builds char_map_{lang}.json from CSV
â”‚   â”‚   â””â”€â”€ trie.py              # Builds trie_{lang}.json + labels_{lang}.txt
â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â”œâ”€â”€ nep/
â”‚   â”‚   â”‚   â”œâ”€â”€ char_map_eng.json
â”‚   â”‚   â”‚   â”œâ”€â”€ char_map_nep.json
â”‚   â”‚   â”‚   â”œâ”€â”€ labels_eng.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ labels_nep.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ trie_eng.json    (~37 KB)
â”‚   â”‚   â”‚   â””â”€â”€ trie_nep.json    (~42 KB)
â”‚   â”‚   â”œâ”€â”€ ind/                 # (India language artifacts)
â”‚   â”‚   â””â”€â”€ som/                 # (Somali/other artifacts)
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ csv/
â”‚       â”‚   â”œâ”€â”€ kataho_nep_sheet.csv        (~200 KB, Nepali dataset)
â”‚       â”‚   â””â”€â”€ nep_kataho_code_eng.csv     (~117 KB, English-coded Nepali)
â”‚       â”œâ”€â”€ train/
â”‚       â”‚   â””â”€â”€ nep/
â”‚       â”‚       â””â”€â”€ train_{lang}.csv        # Columns: input, target
â”‚       â””â”€â”€ samples/
â”‚           â””â”€â”€ nep/
â”‚               â””â”€â”€ repr_samples_{lang}.txt # Representative samples for INT8 calibration
â”‚
â”œâ”€â”€ model_trainings/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ model_training.py    # Train CNN on train_{lang}.csv â†’ .keras file
â”‚   â”‚   â””â”€â”€ convert_tflite.py    # Convert .keras â†’ INT8 quantized .tflite
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ nep/
â”‚           â”œâ”€â”€ cnn_eng.keras    (~1.6 MB, full Keras model â€” English input)
â”‚           â”œâ”€â”€ cnn_nep.keras    (~1.6 MB, full Keras model â€” Nepali input)
â”‚           â”œâ”€â”€ model_eng.tflite (~155 KB, INT8 quantized â€” English)
â”‚           â”œâ”€â”€ model_nep.tflite (~157 KB, INT8 quantized â€” Nepali)
â”‚           â”œâ”€â”€ meta_eng.json    # {"max_len": N}
â”‚           â””â”€â”€ meta_nep.json    # {"max_len": N}
â”‚
â”œâ”€â”€ ETL/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ extractor.py         # Query MySQL feedback â†’ pandas DataFrame
â”‚   â”‚   â”œâ”€â”€ transformer.py       # Drop duplicates, fill NaN
â”‚   â”‚   â””â”€â”€ loader.py            # Group by region/lang â†’ save CSVs
â”‚   â””â”€â”€ csv_exports/
â”‚       â”œâ”€â”€ ind_hin_output.csv
â”‚       â”œâ”€â”€ nep_eng_output.csv
â”‚       â”œâ”€â”€ nep_nep_output.csv
â”‚       â””â”€â”€ usa_eng_output.csv
â”‚
â””â”€â”€ suggest/                     # Python virtual environment (git-ignored)
```

---

## Supported Languages & Regions

| Region | Language Codes | Folder Key | Description |
|--------|----------------|------------|-------------|
| `nepal` | `nep`, `eng` | `nep` | Nepali Unicode output; input can be English romanization or Nepali |
| `india` | `hin`, `ben`, `tam`, `tel` | *(lang code)* | Each Indian language uses its own folder |
| `global` | `eng` | `eng` | General English autocompletion |

> **Folder Key Logic:** The canonical on-disk folder is named after the **target/output language** of the region. For Nepal, all models and artifacts live under `nep/` even when the *input* is English â€” because the *output* is always Nepali Unicode.

---

## Component Deep-Dive

### 1. `config.py` â€” Central Configuration

The **single source of truth** for all file paths, region/language definitions, and runtime constants.

```python
# Key exports:
get_config(region, lang)          # â†’ dict of all resolved absolute paths
prompt_region_and_language()      # â†’ interactive CLI selector â†’ calls get_config()

# Constants:
SUPPORTED   = {"nepal": ["nep","eng"], "india": [...], "global": ["eng"]}
FOLDER_KEY  = {"nepal": "nep", "india": None, "global": "eng"}
DB_CONFIG   = {"host":..., "user":..., "password":..., "database":"autosuggest_db"}
TOKEN_ACCESS_TIME = 120   # minutes
ALGORITHM_NAME    = "HS512"
PORT              = 8001
IP_ADDRESS        = "0.0.0.0"
```

**Resolved path dict (example for nepal/eng):**

| Key | Resolved Path |
|-----|---------------|
| `TRIE_PATH` | `data_preparation/artifacts/nep/trie_eng.json` |
| `CHAR_MAP` | `data_preparation/artifacts/nep/char_map_eng.json` |
| `TFLITE_MODEL` | `model_trainings/models/nep/model_nep.tflite` |
| `META_JSON` | `model_trainings/models/nep/meta_nep.json` |
| `TRAIN_CSV` | `data_preparation/data/train/nep/train_eng.csv` |
| `KERAS_FILE` | `model_trainings/models/nep/cnn_eng.keras` |
| `LABELS` | `data_preparation/artifacts/nep/labels_eng.txt` |

---

### 2. Trie Searcher

A **BFS-based prefix trie** built at startup from the training CSV's `input` column.

```
insert("namaste")        â†’ inserts nâ†’aâ†’mâ†’aâ†’sâ†’tâ†’eâ†’{_end}
autocomplete("nam", 500) â†’ BFS from node 'm' â†’ up to 500 words
```

- **API version** (`autocomplete_api.py`): object-oriented `TrieNode` + `TrieSearcher` with `__slots__` for memory efficiency.
- **CLI version** (`autocomplete_main.py`): dict-based trie (simpler, for local testing).

---

### 3. CNN Model & TFLite Inference

**Architecture (`model_training.py`):**
```
Input  (max_len integers)  â†’ int32 sequence
  â†“  Embedding(vocab+1, 32, max_len)
  â†“  Conv1D(128, kernel=3, relu, padding=same)
  â†“  Conv1D(128, kernel=3, relu, padding=same)
  â†“  GlobalMaxPool1D()
  â†“  Dense(128, relu)
  â†“  Dense(num_classes, softmax, float32)
Output  (probability over all vocabulary words)
```

**Training parameters (defaults):**

| Param | Default | Description |
|-------|---------|-------------|
| `--max_len` | 12 | Input sequence length |
| `--emb_dim` | 32 | Embedding dimension |
| `--epochs` | 100 | Max epochs (EarlyStopping patience=10) |
| `--batch` | 128 | Batch size |

**Quantization (`convert_tflite.py`):**
- Full INT8 post-training quantization using representative samples.
- Reduces model size: ~1.6 MB Keras â†’ ~155 KB TFLite.
- Inference uses dequantization formula: `float = scale Ã— (int8 âˆ’ zero_point)`.

---

### 4. FastAPI Backend (`autocomplete_api.py`)

| Aspect | Detail |
|--------|--------|
| **Startup** | `lifespan` context manager loads CSV, builds Trie, loads char_map, loads TFLite, calls `init_db()` |
| **Config** | `_resolve_config()` checks `REGION`/`LANG` env vars first; falls back to interactive prompt |
| **Port** | `8001` (configurable via `config.py`) |
| **Host** | `0.0.0.0` by default |

**Routes:**

| Method | Path | Auth | Description |
|--------|------|------|-------------|
| `POST` | `/autocomplete/token` | None | Returns an encrypted JWT access token |
| `POST` | `/autocomplete/suggest` | Bearer JWT | Returns top-20 suggestions for a prefix |
| `POST` | `/autocomplete/feedback` | Bearer JWT | Records user's selection in MySQL |

---

### 5. Security Layer (`core/security.py`)

**Double-layer token protection:**
1. **JWT** (HS512): signed with `JWT_SECRET_KEY`, contains `sub="api_client"` + expiry.
2. **Fernet (AES-128-CBC + HMAC)**: JWT string is symmetrically encrypted with `FERNET_KEY` before being sent to clients. Clients send the opaque Fernet-encrypted blob as a Bearer token.

**Flow:**
```
Server                              Client
  â”‚â”€â”€ POST /autocomplete/token â”€â”€â–º  â”‚
  â”‚   create_token({sub:"api_client"})
  â”‚   = jwt.encode(payload, SECRET, HS512)
  â”‚   = fernet.encrypt(jwt_string)
  â”‚â—„â”€â”€ {"access_token": "<fernet_blob>"} â”€â”€â”‚
  â”‚
  â”‚â—„â”€â”€ POST /autocomplete/suggest â”€â”€â”‚
  â”‚    Authorization: Bearer <fernet_blob>
  â”‚   fernet.decrypt(blob) â†’ jwt_string
  â”‚   jwt.decode(jwt_string, SECRET) â†’ payload
  â”‚   â†’ verified, proceed
```

---

### 6. Database Layer (`database/db.py`)

```sql
-- Auto-created on startup
CREATE TABLE IF NOT EXISTS feedback (
    input       VARCHAR(255)  NOT NULL,
    label       VARCHAR(255)  NOT NULL,
    rank_score  INT           NOT NULL DEFAULT 0,
    region      VARCHAR(255)  NOT NULL,
    lang        VARCHAR(255)  NOT NULL,
    PRIMARY KEY (input, label)
);
```

| Function | SQL Operation |
|----------|---------------|
| `init_db()` | `CREATE TABLE IF NOT EXISTS feedback` |
| `update_rank(inp, label)` | `INSERT ... ON DUPLICATE KEY UPDATE rank_score = rank_score + 1` |
| `get_rank(label)` | `SELECT SUM(rank_score) FROM feedback WHERE label = ?` |

**Connection pool:** `pool_size=5`, managed by `mysql.connector.pooling.MySQLConnectionPool`.

---

### 7. ETL Pipeline (`csv_extractor.py` + `ETL/`)

Used to export feedback data from MySQL back to CSV for retraining or analysis.

```
csv_extractor.py
    â”‚
    â”œâ”€â”€ ETL/utils/extractor.py    â†’ SELECT * FROM feedback
    â”œâ”€â”€ ETL/utils/transformer.py  â†’ drop_duplicates(), fillna("")
    â””â”€â”€ ETL/utils/loader.py       â†’ groupby(region, lang) â†’ ETL/csv_exports/{region}_{lang}_output.csv
```

---

## Data Flow

### Inference Request Flow

```
User types prefix "na"
        â”‚
        â–¼
  [Frontend JS]  POST /autocomplete/suggest  {text: "na"}
        â”‚  Bearer: <fernet_jwt>
        â–¼
  [security.py]  decrypt fernet â†’ decode JWT â†’ verify expiry
        â”‚
        â–¼
  [autocomplete_api.py  _score_candidates()]
        â”œâ”€â”€ TrieSearcher.autocomplete("na", limit=500)  â†’ ["namaste", "nachari", ...]
        â”‚
        â”œâ”€â”€ For each candidate:
        â”‚      encode("na") â†’ int32 array
        â”‚      TFLite interpreter.invoke()
        â”‚      get output probabilities
        â”‚      score = proba[candidate_index]
        â”‚
        â”œâ”€â”€ Sort by score DESC â†’ map inputâ†’target (eng_to_nep dict) â†’ deduplicate â†’ top-20
        â”‚
        â””â”€â”€ DB: SELECT label, rank_score FROM feedback WHERE input LIKE "na%"
                 â†’ merge (DB lower rank_score = higher priority)
        â”‚
        â–¼
  {data: [{label: "à¤¨à¤®à¤¸à¥à¤¤à¥‡"}, {label: "à¤¨à¤šà¤¾à¤°à¥€"}, ...]}
        â”‚
        â–¼
  [Frontend]  render dropdown â†’ user clicks "à¤¨à¤®à¤¸à¥à¤¤à¥‡"
        â”‚
        â–¼
  POST /autocomplete/feedback  {input: "na", label: "à¤¨à¤®à¤¸à¥à¤¤à¥‡"}
        â”‚
        â–¼
  [db.py update_rank]  INSERT ... ON DUPLICATE KEY UPDATE rank_score = rank_score + 1
```

---

## Quickstart (Local Dev)

### Prerequisites

- Python 3.10+
- MySQL 8.x running locally
- `pip`

### Steps

```bash
# 1. Clone and enter the project
cd Autosuggestion_Engine

# 2. Create and activate virtual environment
python -m venv suggest
suggest\Scripts\activate          # Windows
# source suggest/bin/activate     # Linux/macOS

# 3. Install dependencies
pip install -r requirements.txt

# 4. Set secrets (copy .env and fill in values)
#    Minimum required: JWT_SECRET_KEY and FERNET_KEY
#    See Environment Variables section below for generation commands

# 5. Run the database migration
python migration.py

# 6. Start the API server (interactive region/lang prompt)
python web\backend\autocomplete_api.py

# 7. Open the frontend
#    Open web/frontend/index.html directly in a browser
#    The JS fetches http://127.0.0.1:8001 by default
```

### CLI Debug Mode

```bash
# Interactive suggestion tester â€” no server needed
python autocomplete_main.py
# â†’ Prompts for region & language
# â†’ Then: prefix > na
# â†’   Suggestions: ['à¤¨à¤®à¤¸à¥à¤¤à¥‡', 'à¤¨à¤¾à¤®', ...]
```

---

## Production Deployment

### Option 1: Direct (Systemd / Process Manager)

```bash
# Set environment variables (do NOT use .env in production)
export JWT_SECRET_KEY="<your-64-char-hex>"
export FERNET_KEY="<your-fernet-base64-url-key>"
export CORS_ORIGINS="https://yourdomain.com"
export REGION="nepal"
export LANG="nep"

# Run with Uvicorn (production grade)
uvicorn web.backend.autocomplete_api:app \
  --host 0.0.0.0 \
  --port 8001 \
  --workers 1 \
  --log-level info
```

> âš ï¸ **Set `--workers 1`** because the TFLite interpreter is loaded into process memory at startup. Multi-worker setups require each worker to load its own interpreter (handled correctly by `lifespan`).

### Option 2: Docker

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . .

RUN pip install --no-cache-dir -r requirements.txt

# Secrets injected at runtime, not baked into image
ENV JWT_SECRET_KEY=""
ENV FERNET_KEY=""
ENV CORS_ORIGINS="https://yourdomain.com"
ENV REGION="nepal"
ENV LANG="nep"

EXPOSE 8001

CMD ["uvicorn", "web.backend.autocomplete_api:app", \
     "--host", "0.0.0.0", "--port", "8001", "--workers", "1"]
```

```bash
docker build -t autosuggest .
docker run -d \
  -e JWT_SECRET_KEY="<key>" \
  -e FERNET_KEY="<key>" \
  -e CORS_ORIGINS="https://yourdomain.com" \
  -e REGION="nepal" \
  -e LANG="nep" \
  -p 8001:8001 \
  autosuggest
```

### Option 3: Nginx Reverse Proxy

```nginx
server {
    listen 443 ssl;
    server_name api.yourdomain.com;

    location / {
        proxy_pass http://127.0.0.1:8001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

---

## Environment Variables

| Variable | Required | Example | Description |
|----------|----------|---------|-------------|
| `JWT_SECRET_KEY` | âœ… Yes | `8c8d6e01...` | 32-byte hex string for JWT signing |
| `FERNET_KEY` | âœ… Yes | `yH52MtY4...=` | URL-safe base64 Fernet key for token encryption |
| `CORS_ORIGINS` | âš ï¸ Prod | `https://app.com` | Comma-separated allowed origins; `*` for dev |
| `REGION` | âœ… Server | `nepal` | Locks region for non-interactive startup |
| `LANG` | âœ… Server | `nep` | Locks language for non-interactive startup |

**Generate secrets:**
```bash
# JWT secret key
python -c "import secrets; print(secrets.token_hex(32))"

# Fernet key
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```

---

## API Reference Summary

### POST `/autocomplete/token`
- **Auth:** None
- **Body:** None
- **Response:** `{"access_token": "<fernet_encrypted_jwt>"}`

### POST `/autocomplete/suggest`
- **Auth:** `Authorization: Bearer <token>`
- **Body:** `{"text": "na"}`
- **Response:** `{"data": [{"label": "à¤¨à¤®à¤¸à¥à¤¤à¥‡"}, ...]}`

### POST `/autocomplete/feedback`
- **Auth:** `Authorization: Bearer <token>`
- **Body:** `{"input": "na", "label": "à¤¨à¤®à¤¸à¥à¤¤à¥‡"}`
- **Response:** `{"status": "success"}`

> Full API documentation: [`docs/API_REFERENCE.md`](docs/API_REFERENCE.md)

---

## Model Architecture

```
Input: char-encoded prefix (int32, padded to max_len=12)

Embedding Layer  â†’  (max_len, 32)
Conv1D (128, k=3, relu, same)  â†’  (max_len, 128)
Conv1D (128, k=3, relu, same)  â†’  (max_len, 128)
GlobalMaxPool1D  â†’  (128,)
Dense (128, relu)  â†’  (128,)
Dense (num_classes, softmax)   â†’  (num_classes,)

Loss: sparse_categorical_crossentropy
Optimizer: Adam
EarlyStopping: patience=10, restore_best_weights=True
```

**Files per language variant:**

| File | Size | Purpose |
|------|------|---------|
| `cnn_{lang}.keras` | ~1.6 MB | Full Keras model (training only) |
| `model_{lang}.tflite` | ~155â€“160 KB | INT8 quantized (inference) |
| `meta_{lang}.json` | 30 B | `{"max_len": N}` |
| `char_map_{lang}.json` | ~0.5â€“1.1 KB | `{"a": 1, "b": 2, ...}` |
| `labels_{lang}.txt` | ~2â€“6 KB | Vocabulary words, one per line |
| `trie_{lang}.json` | ~38â€“43 KB | Serialized prefix trie |

---

## Feedback Learning Loop

```
1. User queries â†’ model returns top-20
2. User clicks suggestion X
3. POST /feedback  {input: prefix, label: X}
4. DB: feedback(input, label).rank_score += 1
5. Next query for same prefix:
   - DB result: (X, rank_score=1) â† lower score = higher priority
   - Model result: (X, 999)       â† model items always get score=999
   â†’ DB wins, X appears first
6. Export: python csv_extractor.py
   â†’ ETL extracts feedback â†’ CSVs in ETL/csv_exports/
   â†’ Can be merged into train CSV for next model retrain cycle
```

---

## Project Conventions

| Convention | Detail |
|------------|--------|
| **Path resolution** | All paths resolved via `config.get_config(region, lang)` â€” never hardcoded in source files |
| **Config loading** | `sys.path.insert(0, project_root)` pattern used throughout to enable `from config import ...` |
| **Secrets** | Only from env vars (`os.environ.get`); `.env` for local dev via `python-dotenv`, never committed |
| **DB** | Connection pool only; `get_connection()` always called inside `try/finally` to return connections |
| **TFLite** | INT8 dequantization check on every inference call (handles both quantized and float outputs) |
| **Logging** | `logging.basicConfig` at API level; `logging.getLogger(__name__)` in each module |

---

## Documentation Index

| Document | Description |
|----------|-------------|
| [README.md](README.md) | This file â€” full project overview |
| [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) | Detailed component architecture with diagrams |
| [docs/API_REFERENCE.md](docs/API_REFERENCE.md) | Complete API endpoint documentation |
| [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) | Step-by-step deployment guide |
| [docs/DATA_PIPELINE.md](docs/DATA_PIPELINE.md) | ETL, preprocessing, and model training pipeline |
